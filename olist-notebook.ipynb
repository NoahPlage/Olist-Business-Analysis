{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# for connection with Azure SQL Database\n",
    "import pyodbc\n",
    "import urllib\n",
    "import sqlalchemy\n",
    "\n",
    "# for keeping credentials out of sight\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credentials and Authorization\n",
    "\n",
    "You will need to insert your database connection parameters and save as `sql-keys.env` local file.\n",
    "\n",
    "```\n",
    "DB_SERVER = \"XXXXX\"\n",
    "DB_NAME = \"XXXXX\" \n",
    "DB_USERNAME = \"XXXXX\"\n",
    "DB_PASSWORD = XXXXX\n",
    "```\n",
    "The following is the list of the connection parameters:\n",
    "- *DB_SERVER*: database server address e.g., localhost or an IP address.\n",
    "- *DB_NAME*: the name of the database that you want to connect.\n",
    "- *DB_USERNAME*: the username used to authenticate.\n",
    "- *DB_PASSWORD*: password used to authenticate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish working directory path\n",
    "# getcwd() returns current working directory\n",
    "wdir_path = os.getcwd()\n",
    "\n",
    "sql_path = os.path.join(wdir_path, \"sql-keys.env\") # absolute path of \"sql-keys.env\"\n",
    "# load the credentials into os environment \n",
    "load_dotenv(sql_path)\n",
    "# check if credentials loaded successfully\n",
    "os.environ\n",
    "\n",
    "# getting credentials information from \"sql-keys.env\"\n",
    "server = os.getenv(\"DB_SERVER\")\n",
    "database = os.getenv(\"DB_NAME\")\n",
    "username = os.getenv(\"DB_USERNAME\")\n",
    "password = os.getenv(\"DB_PASSWORD\")\n",
    "\n",
    "driver = ''\n",
    "# retriving ODBC Driver information from user's computer using Pyodbc\n",
    "driver_names = [x for x in pyodbc.drivers() if x.endswith(' for SQL Server')]\n",
    "if driver_names:\n",
    "    driver = driver_names[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connection to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to database created successfully.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # if driver exists, create connection with Azure SQL Database\n",
    "    if driver:\n",
    "        conn_string = \"DRIVER={\" + driver + \"};SERVER=\" + server + \";DATABASE=\" + database + \";UID=\" + username + \";PWD=\" + password\n",
    "                \n",
    "        # According to SQLAlchemy's documentation, an exact PyODBC connection string can be\n",
    "        # sent in pyodbc's format directly using the parameter odbc_connect.\n",
    "        # As the delimiters need to be URL-encoded (especially the Driver), urllib.parse.quote_plus is used\n",
    "        # to encode the PyODBC connection string.\n",
    "        db_params = urllib.parse.quote_plus(conn_string)\n",
    "        engine = sqlalchemy.create_engine(\"mssql+pyodbc:///?odbc_connect={}\".format(db_params), fast_executemany=True)\n",
    "        \n",
    "        # establish the connection\n",
    "        cnxn = engine.raw_connection()\n",
    "\n",
    "        # create a cursor object\n",
    "        cursor = cnxn.cursor()\n",
    "\n",
    "        print(\"Connection to database created successfully.\")\n",
    "    else:\n",
    "        print(\"No suitable driver found. Cannot connect.\")\n",
    "except Exception as e:\n",
    "    print(\"Connection could not be made due to the following error: \\n\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Tables into Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "olist_sellers successfully created.\n",
      "olist_customers successfully created.\n",
      "olist_geolocation successfully created.\n"
     ]
    }
   ],
   "source": [
    "def create_table(command, msg):\n",
    "    '''\n",
    "    Function to create table into Azure database\n",
    "    \n",
    "    Parameters:\n",
    "        command (string): SQL statement to create new table in database\n",
    "        msg (string): A string message to print that table is successfully created\n",
    "    '''\n",
    "    try:\n",
    "        cursor.execute(command)\n",
    "        cnxn.commit()     \n",
    "    except Exception as e:\n",
    "        # rollback current transaction if there is an error\n",
    "        cnxn.rollback()\n",
    "        raise e\n",
    "    print(msg)\n",
    "\n",
    "# create olist_sellers table\n",
    "create_table(\"\"\"\n",
    "            IF OBJECT_ID('dbo.olist_sellers', 'U') IS NULL \n",
    "            BEGIN\n",
    "                CREATE TABLE olist_sellers\n",
    "                (\n",
    "                    seller_id VARCHAR(255) PRIMARY KEY NOT NULL, \n",
    "                    seller_zip_code_prefix INT, \n",
    "                    seller_city VARCHAR(255), \n",
    "                    seller_state VARCHAR(2)\n",
    "                )\n",
    "            END;\n",
    "            \"\"\",\n",
    "            \"olist_sellers successfully created.\")\n",
    "\n",
    "# create olist_customers table\n",
    "create_table(\"\"\"\n",
    "            IF OBJECT_ID('dbo.olist_customers', 'U') IS NULL \n",
    "            BEGIN\n",
    "                CREATE TABLE olist_customers \n",
    "                (\n",
    "                    customer_id VARCHAR(255) PRIMARY KEY NOT NULL,\n",
    "                    customer_unique_id VARCHAR(255) NOT NULL, \n",
    "                    customer_zip_code_prefix INT, \n",
    "                    customer_city VARCHAR(255), \n",
    "                    customer_state VARCHAR(2)\n",
    "                )\n",
    "            END;\n",
    "            \"\"\",\n",
    "            \"olist_customers successfully created.\")\n",
    "\n",
    "# create olist_geolocation\n",
    "create_table(\"\"\"\n",
    "            IF OBJECT_ID('dbo.olist_geolocation', 'U') IS NULL \n",
    "            BEGIN\n",
    "                CREATE TABLE olist_geolocation \n",
    "                (\n",
    "                    geolocation_zip_code_prefix INT PRIMARY KEY NOT NULL,\n",
    "                    geolocation_lat DECIMAL NOT NULL, \n",
    "                    geolocation_lng DECIMAL NOT NULL\n",
    "                )\n",
    "            END;\n",
    "            \"\"\",\n",
    "            \"olist_geolocation successfully created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer data\n",
    "\n",
    "The `olist_customers_dataset` contains location informations of the customer.\n",
    "- `customer_unique_id` is a unique id identifying customers in the system. It is an id generated at the time of **signup**.\n",
    "- `customer_id` is a temporary id generated everytime the customer places an order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_unique_id</th>\n",
       "      <th>customer_zip_code_prefix</th>\n",
       "      <th>customer_city</th>\n",
       "      <th>customer_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06b8999e2fba1a1fbc88172c00ba8bc7</td>\n",
       "      <td>861eff4711a542e4b93843c6dd7febb0</td>\n",
       "      <td>14409</td>\n",
       "      <td>franca</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18955e83d337fd6b2def6b18a428ac77</td>\n",
       "      <td>290c77bc529b7ac935b93aa66c333dc3</td>\n",
       "      <td>9790</td>\n",
       "      <td>sao bernardo do campo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4e7b3e00288586ebd08712fdd0374a03</td>\n",
       "      <td>060e732b5b29e8181a18229c7b0b2b5e</td>\n",
       "      <td>1151</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b2b6027bc5c5109e529d4dc6358b12c3</td>\n",
       "      <td>259dac757896d24d7702b9acbbff3f3c</td>\n",
       "      <td>8775</td>\n",
       "      <td>mogi das cruzes</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4f2d8ab171c80ec8364f7c12e35b23ad</td>\n",
       "      <td>345ecd01c38d18a9036ed96c73b8d066</td>\n",
       "      <td>13056</td>\n",
       "      <td>campinas</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        customer_id                customer_unique_id  \\\n",
       "0  06b8999e2fba1a1fbc88172c00ba8bc7  861eff4711a542e4b93843c6dd7febb0   \n",
       "1  18955e83d337fd6b2def6b18a428ac77  290c77bc529b7ac935b93aa66c333dc3   \n",
       "2  4e7b3e00288586ebd08712fdd0374a03  060e732b5b29e8181a18229c7b0b2b5e   \n",
       "3  b2b6027bc5c5109e529d4dc6358b12c3  259dac757896d24d7702b9acbbff3f3c   \n",
       "4  4f2d8ab171c80ec8364f7c12e35b23ad  345ecd01c38d18a9036ed96c73b8d066   \n",
       "\n",
       "   customer_zip_code_prefix          customer_city customer_state  \n",
       "0                     14409                 franca             SP  \n",
       "1                      9790  sao bernardo do campo             SP  \n",
       "2                      1151              sao paulo             SP  \n",
       "3                      8775        mogi das cruzes             SP  \n",
       "4                     13056               campinas             SP  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dataset\n",
    "cust_df = pd.read_csv(\"data/olist_customers_dataset.csv\")\n",
    "\n",
    "# view dataset\n",
    "cust_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows in olist_customers_dataset: 99441\n",
      "\n",
      "Number of unique values in each column:\n",
      "customer_id                 99441\n",
      "customer_unique_id          96096\n",
      "customer_zip_code_prefix    14994\n",
      "customer_city                4119\n",
      "customer_state                 27\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of rows in olist_customers_dataset: \" + str(len(cust_df)))\n",
    "\n",
    "# determine the number of unique values in each column\n",
    "print(\"\\nNumber of unique values in each column:\")\n",
    "print(cust_df.nunique(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert into Azure SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "olist_customers successfully updated.\n"
     ]
    }
   ],
   "source": [
    "def write_df(df_name, table_name, msg):\n",
    "    '''\n",
    "    Function to insert values from dataframe into Azure database\n",
    "    \n",
    "    Parameters:\n",
    "        df_name (DataFrame): DataFrame name to get data from\n",
    "        table_name (string): Table name to update in SQL Azure Database\n",
    "        msg (string): A string message to print that table is successfully updated\n",
    "    '''\n",
    "    try:\n",
    "        df_name.to_sql(table_name, engine, index=False, if_exists=\"append\", schema=\"dbo\")\n",
    "        cnxn.commit()     \n",
    "    except Exception as e:\n",
    "        # rollback current transaction if there is an error\n",
    "        cnxn.rollback()\n",
    "        raise e\n",
    "    print(msg)\n",
    "\n",
    "# insert data into olist_customers table\n",
    "write_df(cust_df, \"olist_customers\", \"olist_customers successfully updated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "cnxn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `olist_geolocation_dataset` contains latitude and longitude points, city and state for the zipcodes. Every customer in the customer dataset has a zipcode associated as their location within the state and city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "geo_df = pd.read_csv('data/olist_geolocation_dataset.csv')\n",
    "\n",
    "# view dataset\n",
    "geo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### olist_order_reviews_dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review_id: unique review identifier\n",
    "# order_id: unique order identifier\n",
    "# review_score: Note ranging from 1 to 5 given by the customer on a satisfaction survey\n",
    "# review_comment_title: Comment title from the review left by the customer, in Portuguese\n",
    "# review_comment_message: Comment message from the review left by the customer, in Portuguese\n",
    "# review_creation_date: Shows the date in which the satisfaction survey was sent to the customer\n",
    "# review_answer_timestamp: Shows satisfaction survey answer timestamp\n",
    "\n",
    "# Read in olist_order_reviews_dataset.csv as pandas dataframe and parse dates of \n",
    "# \"review_creation_date\" and \"review_answer_timestamp\" columns.\n",
    "parse_dates = [\"review_creation_date\", \"review_answer_timestamp\"]\n",
    "order_reviews_data = pd.read_csv(\"olist_order_reviews_dataset.csv\",\\\n",
    "                                 infer_datetime_format = True, parse_dates = parse_dates)\n",
    "\n",
    "# Drop duplicates from review_id column.\n",
    "order_reviews_data.drop_duplicates(subset = ['review_id'], inplace = True)\n",
    "\n",
    "# Preview the first 5 lines of the loaded data \n",
    "order_reviews_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of entries in each column\n",
    "order_reviews_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of unique entries\n",
    "order_reviews_data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values\n",
    "order_reviews_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with null values\n",
    "order_reviews_data.drop(columns = [\"review_comment_title\", \"review_comment_message\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check datatypes\n",
    "order_reviews_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change column to datetime\n",
    "order_reviews_data['review_answer_timestamp'] = order_reviews_data['review_answer_timestamp'].dt.date\n",
    "order_reviews_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check datatypes\n",
    "order_reviews_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "olist_order_payments_dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order_id: unique order identifier\n",
    "# payment_sequential: a customer may pay an order with more than one payment method. If he does so, a sequence will be created to\n",
    "# payment_type: method of payment chosen by the customer\n",
    "# payment_installments: number of installments chosen by the customer\n",
    "# payment_value: transaction value\n",
    "\n",
    "# Boleto payments: Boleto is an official (regulated by the Central Bank of Brazil) payment method in Brazil. \n",
    "# To complete a transaction, customers receive a voucher stating the amount to pay for services or goods. \n",
    "# Customers then pay the boleto before its expiration date in one of several different methods, including at authorized agencies or banks, ATMs, or online bank portals. \n",
    "# You will receive payment confirmation after 1 business day, while funds will be available for payout 2 business days after payment confirmation.\n",
    "# https://stripe.com/docs/payments/boleto \n",
    "# https://www.rapyd.net/blog/what-is-boleto-everything-you-need-to-know/ \n",
    "\n",
    "# Read in olist_order_payments_dataset.csv and make pandas dataframe\n",
    "order_payment_data = pd.read_csv(\"C:/Users/Mavis Luo/Downloads/Final Year Project/Dataset/olist_order_payments_dataset.csv\")\n",
    "\n",
    "# Drop duplicates from order_id column\n",
    "order_payment_data.drop_duplicates(subset = ['order_id'], inplace = True)\n",
    "\n",
    "# Set index as order_id\n",
    "order_payment_data.set_index(\"order_id\", inplace = True)\n",
    "\n",
    "# Print dataframe\n",
    "order_payment_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count rows of each column\n",
    "order_payment_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of unique entries\n",
    "order_payment_data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print dataframe\n",
    "order_payment_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values\n",
    "order_payment_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check datatypes\n",
    "order_payment_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments = olist_order_reviews.loc[:, ['review_score', 'review_comment_message']]\n",
    "df_comments = df_comments.dropna(subset=['review_comment_message'])\n",
    "df_comments = df_comments.reset_index(drop=True)\n",
    "print(f'Dataset shape: {df_comments.shape}')\n",
    "df_comments.columns = ['score', 'comment']\n",
    "df_comments.head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d888e4012f630a1791b605dfe07b25ffc379762a6d5a9edc260a72f30d593570"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
